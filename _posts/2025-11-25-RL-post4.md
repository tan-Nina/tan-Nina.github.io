---
title: InfoNCE Loss
date: 2025-11-25 18:00:00 +0800
categories: [强化学习, 概念]
math: true
---

InfoNCE (Information Noise Contrastive Estimation) 是**对比学习（Contrastive Learning）**中常用的损失函数。它的核心逻辑不是“预测数值”，而是“分类” 。

**InfoNCE 的目标**就是训练一个模型，让它能从一堆“负样本”中，准确地把“正样本”挑出来。



**数学：**
本质上就是一个**Softmax分类器**：

$$\mathcal{L} = -\sum \log \left( \frac{e^{f(s, a, g)}}{\sum_{j} e^{f(s, a, g_j)}} \right)$$

模型需要最大化分子（正样本的相似度），同时最小化分母（所有样本的相似度总和）。这会迫使模型将正样本“拉近”，将负样本“推开” 。


将GCRL与InfoNCE能解决RL中的**表示学习（Representation Learning）**问题 。

在扩展强化学习（Scaling RL）的研究中，我们不再依赖稀疏的外部奖励，而是利用 InfoNCE 做**自监督学习**：

1.  **数据的来源**：智能体在环境中随机跑，收集一条轨迹序列 。
2.  **构建对比**：
    * **Anchor**：当前状态 $s_t$。
    * **Positive**：同一条轨迹中，未来的某个状态 $s_{t+k}$（因为它是我们实际到达的“目标”）。
    * **Negative**：其他随机轨迹中的状态（是我们没去的地方）。
3.  **训练 Critic**：我们训练一个 Critic 网络来区分“未来会去哪里”和“不会去哪里”。这本质上是在学习一个**以目标为条件的价值函数**，但通过分类任务来实现。

**结论：**
这种结合方式将强化学习转化为了**监督式的分类问题**（Supervised Classification Problem）。深度学习非常擅长做分类，因此这种转化使得我们能够使用更深的网络（如 1000 层 ResNet）来训练强化学习智能体，而不会像传统 RL 那样容易训练崩溃 。

