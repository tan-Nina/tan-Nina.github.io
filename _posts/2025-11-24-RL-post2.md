---
title: å¼ºåŒ–å­¦ä¹ æ·±åº¦æ‰©å±•é—®é¢˜
date: 2025-11-22 18:00:00 +0800
categories: [å¼ºåŒ–å­¦ä¹ , æ–‡çŒ®é˜…è¯»ç¬”è®°]
math: true
---



## 1.èƒŒæ™¯

åœ¨è¿‡å»ï¼ŒRLçš„ç ”ç©¶äººå‘˜å‘ç°ï¼Œç®€å•çš„å¢åŠ ç½‘ç»œæ·±åº¦é€šå¸¸ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™æˆ–è®­ç»ƒä¸ç¨³å®šã€‚æ™®éè®¤ä¸ºï¼ŒRLçš„åé¦ˆä¿¡å·ç¨€ç–ã€å™ªéŸ³å¤§ï¼Œåœ¨æ‰©å±•åˆ°å¤§æ¨¡å‹æ—¶å¾€å¾€é¢ä¸´æŒ‘æˆ˜ã€‚

æ‰€ä»¥ï¼Œç›®å‰çš„æ ‡å‡†åšæ³•é€šå¸¸æ˜¯ï¼š

**ç½‘ç»œå±‚æ•°**ï¼š2-4å±‚å…¨è¿æ¥å±‚ï¼ˆMLPï¼‰ã€‚
**ä¸»è¦ç®—æ³•**ï¼šSAC, TD3, PPOç­‰ã€‚

---
## 2. è§£å†³æ–¹æ¡ˆ
### 2024ï¼ŒFarebrother et al.
åœ¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDeep RLï¼‰ä¸­ï¼Œå°†ä»·å€¼å‡½æ•°çš„è®­ç»ƒä»ä¼ ç»Ÿçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å›å½’é—®é¢˜è½¬åŒ–ä¸ºåˆ†ç±»é—®é¢˜ï¼ˆä½¿ç”¨åˆ†ç±»äº¤å‰ç†µæŸå¤±ï¼‰ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ç®—æ³•çš„æ€§èƒ½ã€é²æ£’æ€§ä»¥åŠåœ¨å¤§è§„æ¨¡ç¥ç»ç½‘ç»œæ¶æ„ä¸‹çš„å¯æ‰©å±•æ€§ ã€‚


#### A. æ ¸å¿ƒæ–¹æ³• (HL-Gauss)
æ–‡ç« ä¸»è¦æ¨å´‡çš„æ–¹æ³•æ˜¯ **Histogram Loss with Gaussian Smoothing (HL-Gauss)**ã€‚

* **åˆ©ç”¨åºæ•°ç»“æ„**ï¼šè¿™ç§æ–¹æ³•åˆ©ç”¨äº†å›å½’ä»»åŠ¡çš„åºæ•°ç»“æ„ï¼ˆordinal structureï¼‰ï¼Œä¸ä»…ä»…æ˜¯å°†ç›®æ ‡ç¦»æ•£åŒ–ï¼Œè€Œæ˜¯é€šè¿‡é«˜æ–¯å¹³æ»‘å°†æ¦‚ç‡è´¨é‡åˆ†é…ç»™ç›®æ ‡å€¼é™„è¿‘çš„å¤šä¸ªâ€œç±»åˆ«â€ï¼ˆbinsï¼‰ã€‚
* **å¯¹æ¯” Two-Hot**ï¼šç›¸æ¯”äºç®€å•çš„â€œTwo-Hotâ€ç¼–ç ï¼ˆä»…å°†æ¦‚ç‡åˆ†é…ç»™æœ€è¿‘çš„ä¸¤ä¸ªè¾¹ç•Œï¼‰ï¼ŒHL-Gauss ç±»ä¼¼äºç›‘ç£å­¦ä¹ ä¸­çš„æ ‡ç­¾å¹³æ»‘ï¼ˆLabel Smoothingï¼‰ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ•°æ®ã€‚

#### B. ä¸åˆ†å¸ƒå¼ºåŒ–å­¦ä¹  (Distributional RL) çš„åŒºåˆ«
è™½ç„¶è¯¥æ–¹æ³•ä½¿ç”¨äº†ç±»ä¼¼äº C51 çš„åˆ†ç±»è¡¨ç¤ºï¼Œä½†å®ƒå¹¶ä¸ä¸€å®šæ—¨åœ¨å»ºæ¨¡å›æŠ¥çš„éšæœºåˆ†å¸ƒï¼ˆCategorical Distributional RLï¼‰ï¼Œè€Œæ˜¯å…³æ³¨äºä½¿ç”¨åˆ†ç±»æŸå¤±å‡½æ•°ï¼ˆCross-Entropyï¼‰æ¥è®­ç»ƒä»·å€¼å‡½æ•°æœ¬èº«ã€‚

---
### 2025ï¼ŒKevin et al.
æœ¬ç ”ç©¶å¹¶æœªæå‡ºä¸€ç§å…¨æ–°çš„ç®—æ³•èŒƒå¼ï¼Œè€Œæ˜¯è‡´åŠ›äºå°†ç°æœ‰çš„**å¯¹æ¯”å¼ºåŒ–å­¦ä¹ ï¼ˆContrastive Reinforcement Learning, CRLï¼‰**æ¡†æ¶ä¸ç°ä»£æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„è¿›è¡Œç³»ç»Ÿæ€§èåˆï¼Œä»¥æ¢ç©¶æ·±åº¦æ‰©å±•å¯¹å¼ºåŒ–å­¦ä¹ æ€§èƒ½çš„å½±å“ã€‚

#### A. ç®—æ³•åŸºç¡€ï¼šå¯¹æ¯”å¼ºåŒ–å­¦ä¹ (CRL)
æœ¬ç ”ç©¶ä½¿ç”¨å¯¹æ¯”å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥è§£å†³**ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ **[ğŸ‘ˆç‚¹å‡»é˜…è¯»]({% post_url 2025-11-25-RL-post3 %})é—®é¢˜ã€‚ä½œä¸ºä¸€ç§**è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰**ç»å…¸ç®—æ³•ï¼ŒCRLè¿ä½œæœºåˆ¶å¦‚ä¸‹ï¼š
* **æ— å¥–åŠ±è‡ªä¸»æ¢ç´¢ï¼ˆReward-Free Explorationï¼‰ï¼š** åœ¨ç¼ºä¹å¤–éƒ¨å¥–åŠ±ä¿¡å·çš„ç¯å¢ƒä¸­ï¼Œæ™ºèƒ½ä½“ï¼ˆAgentï¼‰å¿…é¡»é€šè¿‡è‡ªä¸»æ¢ç´¢æœºåˆ¶ï¼Œä¹ å¾—åˆ°è¾¾çŠ¶æ€ç©ºé—´ä¸­ä»»æ„æŒ‡å®šç›®æ ‡ï¼ˆArbitrary Goalsï¼‰çš„ç­–ç•¥ã€‚
* **åŸºäº InfoNCE çš„ Critic è®­ç»ƒï¼š** Critic ç½‘ç»œçš„ä¼˜åŒ–é‡‡ç”¨ **InfoNCE æŸå¤±å‡½æ•°**[ğŸ‘ˆç‚¹å‡»é˜…è¯»]({% post_url 2025-11-25-RL-post4 %})ã€‚è¿™ä¸€å…¬å¼åŒ–å¤„ç†å®é™…ä¸Šå°†åŸæœ¬çš„ä»·å€¼ä¼°è®¡é—®é¢˜é‡æ„ä¸º**åˆ†ç±»ä»»åŠ¡ï¼ˆClassification Taskï¼‰**ï¼Œå³åˆ¤åˆ«ç»™å®šçš„çŠ¶æ€-åŠ¨ä½œå¯¹ï¼ˆState-Action Pairï¼‰æ˜¯å¦å±äºé€šå‘ç›®æ ‡çŠ¶æ€çš„æ½œåœ¨è½¨è¿¹ã€‚

#### B. ç½‘ç»œæ¶æ„ï¼šæ·±åº¦æ®‹å·®ç½‘ç»œè®¾è®¡
ä¸ºäº†æ”¯æŒç½‘ç»œæ·±åº¦çš„æ˜¾è‘—æ‰©å±•ï¼ˆScalingï¼‰ï¼Œæœ¬ç ”ç©¶åœ¨æ¶æ„è®¾è®¡ä¸Šå¼•å…¥äº†å…³é”®çš„**æ®‹å·®è¿æ¥ï¼ˆResidual Connectionsï¼‰**æœºåˆ¶ã€‚

* **æ®‹å·®å—å¾®è§‚è®¾è®¡ï¼ˆResidual Block Designï¼‰ï¼š** æ¯ä¸ªæ®‹å·®å—ç”± **4 ä¸ªé‡å¤çš„è®¡ç®—å•å…ƒ**æ„æˆã€‚æ¯ä¸ªå•å…ƒå†…éƒ¨éµå¾ªä»¥ä¸‹ç‰¹å®šçš„å±‚çº§åºåˆ—ï¼š
    1.  **Dense Layer**ï¼ˆå…¨è¿æ¥å±‚ï¼‰ï¼šè´Ÿè´£ç‰¹å¾çš„çº¿æ€§å˜æ¢ã€‚
    2.  **LayerNorm**ï¼ˆå±‚å½’ä¸€åŒ–ï¼‰ï¼šç”¨äºè§„èŒƒåŒ–å±‚æ¿€æ´»å€¼åˆ†å¸ƒã€‚
    3.  **Swish Activation**ï¼ˆSwish æ¿€æ´»å‡½æ•°ï¼‰ï¼šæä¾›éçº¿æ€§è¡¨è¾¾èƒ½åŠ›ã€‚

* **æ·±åº¦ï¼š** æŒ‡æ¶æ„ä¸­æ‰€æœ‰æ®‹å·®å—å†…éƒ¨åŒ…å«çš„ Dense å±‚çš„æ€»é‡ï¼ˆå³ 
  $$ 4 \times N $$
  ï¼‰ã€‚

* **è®­ç»ƒç¨³å®šæ€§ï¼š** å®éªŒè¯æ®è¡¨æ˜ï¼Œ**LayerNorm** ä¸ **Swish æ¿€æ´»å‡½æ•°**çš„ç»“åˆå¯¹äºç»´æŒæ·±å±‚ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°å€¼ç¨³å®šæ€§åŠæ¢¯åº¦ä¼ æ’­è‡³å…³é‡è¦ï¼Œæ˜¯å®ç°æ·±åº¦æ‰©å±•çš„å¿…è¦ç»„ä»¶ã€‚
* 
![Figure 2: Architecture. Our approach integrates
residual connections into both the actor and critic networks of the Contrastive RL algorithm. The depth of this residual architecture is defined as the total number of Dense layers across the residual blocks, which, with our residual block size of 4, equates to 4N.](/assets/img/posts/251124RLpost2/2503.14858.fig2.png){: width="60%" style="display: block; margin: 0 auto;" }


---
## 4. æ·±å±‚ç½‘ç»œçš„ä¼˜åŠ¿ï¼š

#### A. æ›´å¥½åœ°è¡¨å¾

åœ¨ä¸€ä¸ª U å‹è¿·å®«ä¸­ï¼Œæµ…å±‚ç½‘ç»œï¼ˆæ·±åº¦ 4ï¼‰éå¸¸â€œçŸ­è§†â€ã€‚å®ƒåªçœ‹ç›´çº¿è·ç¦»ï¼Œå³ä½¿éš”ç€å¢™ä»ç„¶è§‰å¾—ç¦»ç›®æ ‡è¿‘ï¼Œç»“æœä¸€ç›´æ’å¢™ã€‚è€Œæ·±å±‚ç½‘ç»œï¼ˆæ·±åº¦ 64ï¼‰å­¦ä¼šäº†**çŠ¶æ€è¡¨ç¤ºï¼ˆRepresentationï¼‰**ã€‚å®ƒç†è§£è¿™ä¸ä»…æ˜¯è·ç¦»çš„é—®é¢˜ï¼Œè€Œæ˜¯éœ€è¦ç»•è¿‡å¢™å£æ‰èƒ½åˆ°è¾¾ã€‚å®ƒçš„ä»·å€¼å‡½æ•°çƒ­åŠ›å›¾é¡ºç€è¿·å®«çš„è·¯å¾„å»¶ä¼¸ ã€‚

![Figure 9: Deeper Q-functions are qualitatively different. The shallow depth 4 network (left) naively relies on Euclidean proximity, showing high Q values near the start despite a maze wall. In contrast, the depth 64 network (right) clusters high Q values at the goal, gradually tapering along the interior.](/assets/img/posts/251124RLpost2/2503.14858.fig9.png){: .shadow width="50%" style="display: block; margin: 0 auto;" }

#### B. æ³›åŒ–ä¸æ‹¼æ¥ (Stitching)

æ·±å±‚ç½‘ç»œè¡¨ç°å‡ºæ›´å¼ºçš„æ‹¼æ¥èƒ½åŠ›ï¼Œèƒ½å¤Ÿå°†è®­ç»ƒä¸­çš„çŸ­è·¯å¾„ç‰‡æ®µç»„åˆèµ·æ¥ï¼Œè§£å†³è®­ç»ƒä¸­ä»æœªè§è¿‡çš„é•¿è·ç¦»ç›®æ ‡ä»»åŠ¡ ã€‚
ä½œè€…åšäº†ä¸€ä¸ªæç«¯çš„å®éªŒï¼šè®­ç»ƒæ•°æ®ä¸­ï¼Œèµ·ç‚¹å’Œç»ˆç‚¹éƒ½åœ¨ 3 æ­¥ä»¥å†…ã€‚ä½†åœ¨æµ‹è¯•æ—¶ï¼Œç›®æ ‡åœ¨ 6 æ­¥ä»¥å¤–ã€‚

![Figure 11: Deeper networks exhibit improved generalization. Top: Training on short paths (green) vs Evaluation on long paths (red). Bottom: Performance comparison showing deep networks succeed where shallow ones fail.](/assets/img/posts/251124RLpost2/2503.14858.fig11.png){: width="60%" style="display: block; margin: 0 auto;" }
_Deeper networks exhibit improved generalization. Top: Training on short paths (green) vs Evaluation on long paths (red). Bottom: Performance comparison showing deep networks succeed where shallow ones fail._

#### C. è§£é”äº†å¤§ Batch Size çš„æ½œåŠ›

åœ¨ä¼ ç»Ÿ RL ä¸­ï¼Œå¢å¤§ Batch Sizeå¸¦æ¥çš„æ€§èƒ½æå‡å¹¶ä¸æ˜æ˜¾ã€‚ä½œè€…å‘ç°ï¼Œåªæœ‰å½“ç½‘ç»œ**è¶³å¤Ÿæ·±**çš„æ—¶å€™ï¼Œå¢å¤§Batch Sizeæ‰ä¼šå¸¦æ¥æ€§èƒ½æå‡ã€‚

![Figure 7: Deeper networks unlock batch size scaling. As depth increases from 4 to 64, larger networks can effectively leverage larger batch sizes (darker lines) to achieve further improvements.](/assets/img/posts/251124RLpost2/2503.14858.fig7.jpg){: width="70%" style="display: block; margin: 0 auto;" }

#### D. æ¢ç´¢ä¸è¡¨è¾¾èƒ½åŠ›çš„ååŒï¼ˆSynergy of Exploration & Expressivityï¼‰ï¼š

å®éªŒæ˜¾ç¤ºï¼Œä»…æœ‰æ·±å±‚ç½‘ç»œï¼ˆå¼ºè¡¨è¾¾åŠ›ï¼‰è‹¥æ²¡æœ‰å¥½çš„æ•°æ®ï¼ˆç”±æµ…å±‚æ”¶é›†å™¨æä¾›ï¼‰æ˜¯ä¸å¤Ÿçš„ï¼›ä»…æœ‰å¥½çš„æ•°æ®ï¼ˆç”±æ·±å±‚æ”¶é›†å™¨æä¾›ï¼‰è‹¥ç½‘ç»œå¤ªæµ…ä¹Ÿå­¦ä¸å¥½ ã€‚


å‚è€ƒæ–‡çŒ®ï¼š\
[1] Wang K, Javali I, Bortkiewicz M Ä¹, et al. 1000 layer networks for self-supervised rl: Scaling depth can enable new goal-reaching capabilities[J]. arXiv preprint arXiv:2503.14858, 2025.
